{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5+5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\medical_chatbot_opensource_llm_llama2\\lib\\site-packages\\pinecone\\index.py:4: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "import pinecone\n",
    "from langchain.document_loaders import PyMuPDFLoader,DirectoryLoader, PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import CTransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding model in dimension is 384, this will be useful while creating PINECONE_API_ENV\n",
    "\n",
    "PINECONE_API_KEY = 'XXXXXXXXXXXXXX'\n",
    "PINECONE_API_ENV = 'XXXXXX' \n",
    "\n",
    "embedding_model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the data from pdf\n",
    "\n",
    "def load_pdf(data):\n",
    "   loader =  DirectoryLoader(data,\n",
    "                    glob = '*.pdf',\n",
    "                    loader_cls=PyPDFLoader)\n",
    "   documents = loader.load()\n",
    "\n",
    "   return documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_pdf('data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#page wise data\n",
    "\n",
    "extracted_data[2].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create text chunks\n",
    "\n",
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500 , chunk_overlap = 20)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks = text_split(extracted_data)\n",
    "print('length of text chunks :', len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download embedding model\n",
    "\n",
    "def download_hugging_face_embeddings(embedding_model_name):\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=embedding_model_name)\n",
    "    return embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = download_hugging_face_embeddings(embedding_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_result = embeddings.embed_query('Hello world')\n",
    "print('Length : ', len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing the Pinecone\n",
    "pinecone.init(api_key=PINECONE_API_KEY,\n",
    "              environment=PINECONE_API_ENV)\n",
    "\n",
    "index_name=\"medical-chatbot-opensource-llm-llama2\"\n",
    "\n",
    "#Creating Embeddings for Each of The Text Chunks & storing\n",
    "docsearch=Pinecone.from_texts([t.page_content for t in text_chunks], embeddings, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we already have an index, we can load it like this.\n",
    "pinecone.init(api_key=PINECONE_API_KEY,\n",
    "              environment=PINECONE_API_ENV)\n",
    "\n",
    "index_name=\"medical-chatbot-opensource-llm-llama2\"\n",
    "\n",
    "docsearch = Pinecone.from_existing_index(index_name,embeddings)\n",
    "\n",
    "query = \"what are allergies ?\"\n",
    "\n",
    "docs = docsearch.similarity_search(query, k=3)\n",
    "\n",
    "print(\"Result : \", docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# send these to LLM ang get the correct answer\n",
    "\n",
    "prompt_template=\"\"\"\n",
    "Use the following pieces of information to answer the user's question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\" , \"question\"])\n",
    "chain_type_kwargs={\"prompt\": PROMPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = CTransformers(model = \"model/llama-2-7b-chat.ggmlv3.q4_0.bin\", model_type=\"llama\",\n",
    "                    config = {'max_new_tokens':512,\n",
    "                          'temperature':0.8})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create question answering object\n",
    "\n",
    "qa=RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=docsearch.as_retriever(search_kwargs={'k': 2}),\n",
    "    return_source_documents=True, \n",
    "    chain_type_kwargs=chain_type_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input=input(f\"Input Prompt:\")\n",
    "result=qa({\"query\": user_input})\n",
    "print(\"Response : \", result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ask a question\n",
    "\n",
    "# while True:\n",
    "#     user_input=input(f\"Input Prompt:\")\n",
    "#     result=qa({\"query\": user_input})\n",
    "#     print(\"Response : \", result[\"result\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medical_chatbot_opensource_llm_llama2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
